{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor class\n",
    "#training_data = [np.array(training), np.array(labels)], lyrs = [layers.], raw_data - indicators(dataframe)\n",
    "class predictor:\n",
    "    def __init__(self, lrs, optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.MeanSquaredError(), *args, **kwargs): #it's a regression model so no accuracy here\n",
    "        self.lrs = lrs\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.model = tf.keras.Sequential()\n",
    "        for each in self.lrs: self.model.add(each)\n",
    "        self.model.compile(optimizer = self.optimizer, loss = self.loss)\n",
    "\n",
    "    def train(self, training_data, labels, epochs=100):\n",
    "       self.model.fit(x=training_data, y=labels, epochs=epochs, shuffle=True)\n",
    "\n",
    "    def examine_bias(self, raw_data, training_data, labels):\n",
    "      predicts = [] \n",
    "      biases = []\n",
    "      for i in range(len(labels)-1):\n",
    "        prediction = self.model.predict(training_data[i:i+1])\n",
    "        predicts.append(prediction)\n",
    "        biases.append((labels[i] - prediction)/prediction)\n",
    "\n",
    "      predicts = np.array(predicts)\n",
    "      predicts = np.append(np.array([None]*(len(raw_data) - len(training_data) + 1)), np.reshape(predicts, (predicts.shape[0], )))\n",
    "        \n",
    "      positive = [i for i in biases if i < 0]\n",
    "      negative = [i for i in biases if i > 0]\n",
    "      \n",
    "      avg_positive = sum(positive)/len(positive)\n",
    "      avg_negative = sum(negative)/len(negative)\n",
    "      self.bias = (avg_positive, avg_negative) #estimation of how pessimistic/optimistic the model is\n",
    "    \n",
    "    def pred(self, data):\n",
    "      return self.model.predict(data)\n",
    "    \n",
    "    def make_prediction(self, data):\n",
    "      p = self.pred(data) \n",
    "      return (p+p*self.bias[0], p, p+p*self.bias[1])\n",
    "    \n",
    "\n",
    "## methods for data engineering\n",
    "def calcMACD(data):  #this counts the key statistical indicator for the strategy. MACD in my case\n",
    "    prices = data['Close']\n",
    "    indicator = prices.ewm(span=12, adjust=False, min_periods=12).mean() - prices.ewm(span=26, adjust=False, min_periods=26).mean()\n",
    "    signal = indicator.ewm(span=9, adjust=False, min_periods=9).mean()\n",
    "    d = indicator - signal\n",
    "    return d\n",
    "\n",
    "def ma(data, span):\n",
    "  mean = []\n",
    "  for e in range(len(data[span:])):\n",
    "    mean.append(sum(data[e-span:e])/span)\n",
    "  return np.array(mean)\n",
    "\n",
    "def createdataset(secu):\n",
    "  indicators = pd.DataFrame([])\n",
    "  indicators['open'], indicators['close'], indicators['high'], indicators['low'] = secu.Open[100:], secu.Close[100:], secu.High[100:], secu.Low[100:]\n",
    "  indicators['macdhist'] = calcMACD(secu)[74:]\n",
    "  indicators['ma20'], indicators['ma50'] = ma(secu.Close, 20)[80:], ma(secu.Close, 50)[50:]\n",
    "  return indicators\n",
    "\n",
    "def get_trainingdata(indicators):\n",
    "  training = []\n",
    "  labels = []\n",
    "  training_full = []\n",
    "  for i in range(0, len(indicators)-5):\n",
    "    ins = pd.DataFrame([indicators[i:i+5].open,\n",
    "                        indicators[i:i+5].close,\n",
    "                        indicators[i:i+5].high,\n",
    "                        indicators[i:i+5].low,\n",
    "                        indicators[i:i+5].macdhist,\n",
    "                        indicators[i:i+5].ma20,\n",
    "                        indicators[i:i+5].ma50])\n",
    "\n",
    "    y = indicators.close[i+5]\n",
    "    pic = np.reshape(ins.values, (5, 7, 1))\n",
    "\n",
    "    training.append(pic)\n",
    "    labels.append(y)\n",
    "    training_full.append((pic, y))\n",
    "\n",
    "  training = np.array(training)\n",
    "  labels = np.array(labels)\n",
    "  return training, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gelos\\AppData\\Local\\Temp\\ipykernel_3820\\1000396484.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y = indicators.close[i+5]\n"
     ]
    }
   ],
   "source": [
    "raw = secu\n",
    "indicators = createdataset(raw)\n",
    "training_data, labels = trainingdata(indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrs = [layers.Conv1D(100, kernel_size=2, strides=(2), padding='same', input_shape = [5, 7, 1], activation='sigmoid'),\n",
    "        layers.MaxPooling2D((1, 2)),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.15),\n",
    "\n",
    "        layers.Conv1D(50, kernel_size=3, strides=(2), padding='same', activation='sigmoid'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.15),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(1, activation='relu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = predictor(lyrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['aapl', 'nke', 'nflx','goog','sbux','intc','hmy','jnj']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in f:\n",
    "    secu = yf.download(each, period='10y', interval='1d')\n",
    "    ins = createdataset(secu)\n",
    "    tr, ls = get_trainingdata(ins)\n",
    "    estimator.train(tr, ls, epochs = 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#say, we`re gonna purpose this estimator for the last dataset it was trained with\n",
    "estimator.examine_bias(secu, tr, ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01110723]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[161.26332]], dtype=float32),\n",
       " array([[163.07463]], dtype=float32),\n",
       " array([[164.97105]], dtype=float32))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.make_prediction(tr[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163.99000549316406"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline of creating a predictor object: obj = predictor(lyrs)\n",
    "#                                         train on a variety of securities\n",
    "#                                         obj.examine_bias(on a security that the estimator is purposed for)\n",
    "#                                         ready for making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
